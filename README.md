# Weakly Incremental Learning for Semantic Segmentation with Scribble Annotations
## Pei-Sheng Li
#### PyTorch Implementation

![method](https://raw.githubusercontent.com/Baconbuilder/Scribble_WILSON/master/docs/graph.png)
```
Illustration from "ScribbleSup: Scribble-Supervised Convolutional Networks for Semantic Segmentation"
Di Lin, Jifeng Dai, Jiaya Jia, Kaiming He, and Jian Sun
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016
```

This project introduces a framework for weakly incremental learning in semantic segmentation tasks, aimed at incorporating scribble annotations for efficient model updating. While traditional semantic segmentation approaches have shown remarkable performance, updating models incrementally with new categories remains a challenge. Additionally, the annotation process, particularly pixel-by-pixel annotations, is laborious and time-consuming.

The proposed framework leverages scribble annotations, which offer a more cost-effective alternative to pixel-level annotations. Unlike existing approaches that require offline generation of pseudo-labels, our method utilizes an auxiliary classifier trained with scribble annotations and regulated by the segmentation model to obtain pseudo-supervision online. This facilitates incremental model updates while addressing inherent noise in the annotation process through the use of soft-labels generated by the auxiliary classifier. By leveraging scribble annotations, our approach enhances efficiency and reduces annotation costs, enabling the model to learn to segment new classes incrementally.

## How to run
### Requirements
The code has been tested with the following versions:
```
python == 3.7.16
pytorch == 1.8.0
```
If you want to install a custom environment for this code, you can run the following using [conda](https://docs.conda.io/projects/conda/en/latest/commands/install.html):
```
conda install pytorch torchvision cudatoolkit=11.1 -c pytorch
conda install tensorboard
conda install jupyter
conda install matplotlib
conda install tqdm
conda install imageio

pip install inplace-abn # this should be done using CUDA compiler (same version as pytorch)
pip install wandb # to use the WandB logger
```
The full list of dependencies have been provided in the requirements.txt file.

### Datasets 
Pascal-VOC 2012 is used in this project.


To download the dataset, follow the scripts: `data/download_voc.sh`


If your datasets are in a different folder, make a soft-link from the target dataset to the data folder.
We expect the following tree:
```
data/voc/
    SegmentationClassAug/
        <Image-ID>.png
    JPEGImages/
        <Image-ID>.png
    split/
    ... other files 

```
Be sure not to override the current `voc` directory of the repository. 
We suggest to link the folders inside the voc directory.

Scribble annotations for Pascal-VOC 2012 has already been placed in the `dataset` folder, so just leave it in place. Visit [here](https://jifengdai.org/downloads/scribble_sup/) for more information about the scribble annotations. 

### ImageNet Pretrained Models
After setting the dataset, you download the models pretrained on ImageNet using [InPlaceABN](https://github.com/mapillary/inplace_abn).
[Download](https://drive.google.com/file/d/1rQd-NoZuCsGZ7_l_X9GO1GGiXeXHE8CT/view) the ResNet-101 model (we only need it but you can also [download other networks](https://github.com/mapillary/inplace_abn) if you want to change it).
Then, put the pretrained model in the `pretrained` folder.

### Run!
We provide an example script to run the experiments (see `run.sh`).
In the following, we describe the basic parameter to run an experiment.
First, we assume that we have a command 
```
exp='python -m torch.distributed.launch --nproc_per_node=<num GPUs> --master_port <PORT> run.py --num_workers <N_Workers>'`
```
that allow us to setup the distributed data parallel script.

The first to replicate us, is to obtain the model on the step 0 (base step, fully supervised). You can run:
```
exp --name Base --step 0 --lr 0.01 --bce --dataset <dataset> --task <task> --batch_size 24 --epochs 30 --val_interval 2 [--overlap]
```
where we use `--bce` to train the classifier with the binary cross-entropy. `dataset` is set to `voc`. The task 
are, 
```
voc: (you can set overlap here)
    15-5, 10-10
```

After this, you can run the incremental steps using only image level labels (set the `weakly` parameter).
```
exp --name ours --step 1 --weakly --lr 0.001 --alpha 0.5 --step_ckpt <pretr> --loss_de 1 --lr_policy warmup --affinity \ 
    --dataset <dataset> --task <task> --batch_size 24 --epochs 40 [--overlap]
```
where `pretr` should be the path to the pretrained model (usually `checkpoints/step/<dataset>-<task>/<name>.pth`). 



### Acknowledgments
This adaptation is inspired by and builds upon the "Incremental Learning in Semantic Segmentation from Image Labels" ([WILSON](https://github.com/fcdl94/WILSON)) framework by Fabio Cermelli, Dario Fontanel, Antonio Tavera, Marco Ciccone, and Barbara Caputo. We acknowledge their contributions to the field of semantic segmentation and incremental learning.